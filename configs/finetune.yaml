lr: 6.4e-3
backbone_base_lr: 6.4e-4
layer_decay: 0.65
batch_size: 256
weight_decay: 5.0e-4
epochs: 50
clip_max_norm: 0.1
use_checkpoint: False
bf16: True # Enable bfloat16 mixed precision training
# evaluation
evaluator: voc # options: ["coco","voc"]
eval_during_training: True
eval_epochs: 10
## coco evaluator
eval_size: 512
## voc evaluator
metric: mAP # options: ['mAP', 'recall']
proposal_nums: [100, 300, 1000]
eval_mode: area # options: ['area, '11points']
# scheduler
sched: warmupcos # options: ["step", "warmupcos"]
## step
lr_drop: 100
## warmupcosine
warmup_lr: 1.0e-6
min_lr: 1.0e-6
warmup_epochs: 5
decay_rate: 0.1
# model setting
det_token_num: 60
backbone: dinov3 # options: ["vanilla_vit", "dinov3"]
backbone_size: small
pretrained: True
pretrained_path: # For the DINOv3 backbone, leave blank to use the default HuggingFace repo
unfreeze:
  - all
## vanilla_vit
init_pe_size: [512,864]
mid_pe_size: [512,864]
# Matcher
set_cost_class: 4
set_cost_bbox: 5
set_cost_giou: 2
# Loss coefficients
dice_loss_coef: 1
bbox_loss_coef: 5
giou_loss_coef: 2
eos_coef: 0.2
# dataset parameters
dataset_file: voc # options: ["coco","voc"]
num_classes: 20
coco_path: data/VOC2012_train_val
coco_panoptic_path:
remove_difficult: False

output_dir: outputs/finetune
device: cuda
seed: 42
resume: # resume from checkpoint
start_epoch: 0
eval: False
num_workers: 64
# distributed training parameters
world_size: 1
dist_url: env://