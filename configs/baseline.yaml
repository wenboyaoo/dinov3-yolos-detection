lr: 6.4e-3
backbone_base_lr: 6.4e-4
layer_decay: 1
batch_size: 256
weight_decay: 5.0e-4
epochs: 50
clip_max_norm: 0.1
use_checkpoint: False
bf16: True # Enable bfloat16 mixed precision training
# evaluation
eval_during_training: True
eval_epochs: 10
eval_size: 512
# scheduler
sched: warmupcos # options: ["step", "warmupcos"]
## step
lr_drop: 100
## warmupcosine
warmup_lr: 1.0e-6
min_lr: 1.0e-6
warmup_epochs: 5
decay_rate: 0.1
# model setting
det_token_num: 60
backbone: vanilla_vit # options: ["vanilla_vit", "dinov3"]
backbone_size: small
pretrained: True
pretrained_path: # For the DINOv3 backbone, leave blank to use the default HuggingFace repo
unfreeze:
  - all
## vanilla_vit
init_pe_size: [512,864]
mid_pe_size: [512,864]
# Matcher
set_cost_class: 4
set_cost_bbox: 5
set_cost_giou: 2
# Loss coefficients
dice_loss_coef: 1
bbox_loss_coef: 5
giou_loss_coef: 2
eos_coef: 0.2
# dataset parameters
dataset_file: voc # options: ["coco","voc"]
num_classes: 20
coco_path: data/VOC2012_train_val
coco_panoptic_path:
remove_difficult: False

output_dir: outputs/baseline
device: cuda
seed: 42
resume: # resume from checkpoint
start_epoch: 0
eval: False
num_workers: 224
# distributed training parameters
world_size: 1
dist_url: env://